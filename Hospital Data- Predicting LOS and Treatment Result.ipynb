{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hospital Data on Patient Discharges (2007-2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goals: Predict a patient's length of stay (LOS) and treatment completion result (1=complete/success, 0=not complete/failure) based on medical, demographic, and geographic information. Build two different classification models- one for LOS, one for treatment completion.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniellediehl/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import (train_test_split,KFold)\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data07=pd.read_csv(\"TEDS-D-2007-DS0001-data-excel.tsv\", sep='\\t')\n",
    "data08=pd.read_csv(\"TEDS-D-2008-DS0001-data-excel.tsv\", sep='\\t')\n",
    "data09=pd.read_csv(\"TEDS-D-2009-DS0001-data-excel.tsv\", sep='\\t')\n",
    "data10=pd.read_csv(\"TEDS-D-2010-DS0001-data-excel.tsv\", sep='\\t')\n",
    "data11=pd.read_csv(\"TEDS-D-2011-DS0001-data-excel.tsv\", sep='\\t')\n",
    "data12=pd.read_csv(\"TEDS-D-2012-DS0001-data-excel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Taking a sample of 1000 per year for shorter model training times\n",
    "sample07=data07.sample(n=10000)\n",
    "sample08=data08.sample(n=10000)\n",
    "sample09=data09.sample(n=10000)\n",
    "sample10=data10.sample(n=10000)\n",
    "sample11=data11.sample(n=10000)\n",
    "sample12=data12.sample(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adding sample from all years to one dataframe\n",
    "frames=[sample07,sample08,sample09,sample10,sample11,sample12]\n",
    "full_data=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32962\n",
       "1    27038\n",
       "Name: REASON, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert age to mean age--one less dummy\n",
    "age_dict={2:13, 3:16, 4:19, 5:23, 6:27, 7:32, 8:37, 9:42, 10:47, 11:52, 12:55}\n",
    "def group_age(s):\n",
    "    if s in age_dict.keys():\n",
    "        return age_dict[s]\n",
    "full_data['AGE']=full_data['AGE'].map(group_age)\n",
    "\n",
    "#delete CASEID column\n",
    "del full_data['CASEID']\n",
    "\n",
    "#update REASON column to just 0 or 1's\n",
    "#updating reason column to just 1 and 0's \n",
    "def reason_func(s):\n",
    "    if s==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "##replace NANs with -9\n",
    "full_data=full_data.replace(np.nan, '-9')\n",
    "\n",
    "full_data['REASON']=full_data['REASON'].map(reason_func)\n",
    "full_data['REASON'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniellediehl/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#DUMMY VARIABLES\n",
    "collist = full_data.columns.tolist()\n",
    "#removing numeric and target variables before creating dummies\n",
    "collist.remove('ARRESTS')\n",
    "collist.remove('DAYWAIT')\n",
    "collist.remove('NOPRIOR')\n",
    "collist.remove('NUMSUBS')\n",
    "collist.remove('AGE')\n",
    "collist.remove('LOS')\n",
    "collist.remove('REASON')\n",
    "cat_df = full_data[collist]\n",
    "\n",
    "#make these numbers strings so that get dummies will work\n",
    "for i in cat_df.columns:\n",
    "    cat_df[i]=cat_df[i].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Because most of our variables are categorical variables that are coded numerically, \n",
    "#we decided to convert these to dummy variables.\n",
    "df_with_dummies = pd.get_dummies( cat_df , prefix=cat_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of dummy columns 887\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALCDRUG_0</th>\n",
       "      <th>ALCDRUG_1</th>\n",
       "      <th>ALCDRUG_2</th>\n",
       "      <th>ALCDRUG_3</th>\n",
       "      <th>ALCFLG_0</th>\n",
       "      <th>ALCFLG_1</th>\n",
       "      <th>AMPHFLG_0</th>\n",
       "      <th>AMPHFLG_1</th>\n",
       "      <th>BARBFLG_0</th>\n",
       "      <th>BARBFLG_1</th>\n",
       "      <th>...</th>\n",
       "      <th>SUB3_5</th>\n",
       "      <th>SUB3_6</th>\n",
       "      <th>SUB3_7</th>\n",
       "      <th>SUB3_8</th>\n",
       "      <th>SUB3_9</th>\n",
       "      <th>TRNQFLG_0</th>\n",
       "      <th>TRNQFLG_1</th>\n",
       "      <th>VET_-9</th>\n",
       "      <th>VET_1</th>\n",
       "      <th>VET_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>417373</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021897</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256969</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426395</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729233</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 887 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ALCDRUG_0  ALCDRUG_1  ALCDRUG_2  ALCDRUG_3  ALCFLG_0  ALCFLG_1  \\\n",
       "417373           0          0          0          1         0         1   \n",
       "1021897          0          0          1          0         1         0   \n",
       "1256969          0          0          1          0         1         0   \n",
       "426395           0          0          1          0         1         0   \n",
       "729233           0          1          0          0         0         1   \n",
       "\n",
       "         AMPHFLG_0  AMPHFLG_1  BARBFLG_0  BARBFLG_1  ...    SUB3_5  SUB3_6  \\\n",
       "417373           1          0          1          0  ...         0       0   \n",
       "1021897          1          0          1          0  ...         0       0   \n",
       "1256969          1          0          1          0  ...         0       0   \n",
       "426395           1          0          1          0  ...         0       0   \n",
       "729233           1          0          1          0  ...         0       0   \n",
       "\n",
       "         SUB3_7  SUB3_8  SUB3_9  TRNQFLG_0  TRNQFLG_1  VET_-9  VET_1  VET_2  \n",
       "417373        0       0       0          1          0       0      0      1  \n",
       "1021897       0       0       0          1          0       0      0      1  \n",
       "1256969       0       0       0          1          0       0      0      1  \n",
       "426395        0       0       0          1          0       0      0      1  \n",
       "729233        0       0       0          1          0       0      0      1  \n",
       "\n",
       "[5 rows x 887 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"num of dummy columns\", len(df_with_dummies.columns)\n",
    "df_with_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#add back the numeric columns (age, arrests, daywait, no prior, numsubs)\n",
    "data=df_with_dummies\n",
    "data['AGE']=full_data['AGE']\n",
    "data['ARRESTS']=full_data['ARRESTS'].astype(int)\n",
    "data['DAYWAIT']=full_data['DAYWAIT']\n",
    "data['NOPRIOR']=full_data['NOPRIOR']\n",
    "data['NUMSUBS']=full_data['NUMSUBS']\n",
    "data['LOS']=full_data['LOS']\n",
    "data['REASON']=full_data['REASON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adjusting for missing values for the numeric variables\n",
    "#--replacing the missing value (indicated by -9) with the mode of the variable\n",
    "data['ARRESTS']=data['ARRESTS'].replace(-9,0)\n",
    "data['DAYWAIT']=data['DAYWAIT'].replace(-9,0)\n",
    "data['NOPRIOR']=data['NOPRIOR'].replace(-9,0)\n",
    "data['NOPRIOR']=data['NOPRIOR'].replace(-9,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1     20129\n",
       " 2      7481\n",
       " 36     6094\n",
       " 33     5576\n",
       " 35     5436\n",
       " 34     4657\n",
       " 31     4556\n",
       " 32     3437\n",
       " 37     2633\n",
       "-9         1\n",
       "Name: LOS, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adjusting the LOS variable. According to the codebook, values 31 and above for LOS represent\n",
    "#binned values for the number of days. For example, value 31 represented 31-45 number of days.\n",
    "#We decided to bin the entire LOS variable with the below bins.\n",
    "\n",
    "#bins: 1-15, 16-30, 31-45, 46-60, 61-90, 91-120, 121-180, 181-365, 366+\n",
    "\n",
    "def fix_LOS(s):\n",
    "    if s in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]:\n",
    "        return 1\n",
    "    if s in [16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]:\n",
    "        return 2\n",
    "    else:\n",
    "        return s\n",
    "data['LOS']=data['LOS'].map(fix_LOS)\n",
    "data['LOS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating target variables and splitting data into training and testing set\n",
    "X=data[data.columns[data.columns!='LOS']]\n",
    "X=X[X.columns[X.columns!='REASON']]\n",
    "y_los=data['LOS']\n",
    "y_r=data['REASON']\n",
    "\n",
    "X_train, X_test, y_train_los, y_test_los = train_test_split(X,y_los,test_size = 0.33, random_state=42)\n",
    "X_train, X_test, y_train_r, y_test_r = train_test_split(X,y_r,test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction and Feature Selection Methods: Attempting to reduce dimensions of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA: Principal Components Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X_scaled = preprocessing.scale(X)\n",
    "\n",
    "X_train_scaled, X_test_scaled, y_train_los, y_test_los = train_test_split(X_scaled,y_los,test_size = 0.33, random_state=42)\n",
    "X_train_scaled, X_test_scaled, y_train_r, y_test_r = train_test_split(X_scaled,y_r,test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling the data is important before performing PCA\n",
    "#Without scaling, PCA will load more heavily on variables with greater variances.\n",
    "\n",
    "pca=PCA()\n",
    "pca.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAADICAYAAAAZdw+4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbNSkDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110c19fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.clf()\n",
    "plt.axes([.2, .2, .7, .7])\n",
    "plt.plot(pca.explained_variance_ratio_[:150], linewidth=2)\n",
    "plt.axis('tight')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('explained_variance_')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01465132,  0.02530148,  0.03556478,  0.04420477,  0.05152084,\n",
       "        0.05855347,  0.06480497,  0.07090723,  0.07656572,  0.08205488,\n",
       "        0.08746029,  0.09258456,  0.09747399,  0.10225761,  0.10687724,\n",
       "        0.11143225,  0.11576797,  0.11998532,  0.12405688,  0.12804565,\n",
       "        0.13199205,  0.13584882,  0.13963199,  0.14338447,  0.14710217,\n",
       "        0.15075902,  0.15439723,  0.15800716,  0.16156309,  0.16507904,\n",
       "        0.16856984,  0.17203565,  0.17549629,  0.17893381,  0.18233873,\n",
       "        0.18573907,  0.18910371,  0.1924656 ,  0.19581781,  0.19913683,\n",
       "        0.20243725,  0.20569115,  0.20893892,  0.21211694,  0.21526171,\n",
       "        0.21837834,  0.22146511,  0.22453896,  0.22758206,  0.2306078 ,\n",
       "        0.23361239,  0.2366026 ,  0.23957375,  0.24252266,  0.24544735,\n",
       "        0.24834602,  0.25122929,  0.25407755,  0.25687852,  0.25963925,\n",
       "        0.26239865,  0.26514467,  0.26787961,  0.27058636,  0.27325987,\n",
       "        0.27589188,  0.2784754 ,  0.28104705,  0.28358058,  0.28605536,\n",
       "        0.28849447,  0.29091889,  0.2933302 ,  0.2957363 ,  0.29813847,\n",
       "        0.30052308,  0.30289137,  0.30525427,  0.30759957,  0.3099408 ,\n",
       "        0.31227495,  0.31460554,  0.31693243,  0.31925042,  0.32156634,\n",
       "        0.32387729,  0.32618426,  0.32848962,  0.33079119,  0.33309047,\n",
       "        0.33538774,  0.33768256,  0.33997431,  0.34226461,  0.34455375,\n",
       "        0.34684199,  0.34912723,  0.35141178,  0.35369482,  0.35597668,\n",
       "        0.35825681,  0.36053559,  0.3628131 ,  0.36509016,  0.36736653,\n",
       "        0.36964217,  0.3719173 ,  0.37419095,  0.37646295,  0.37873445,\n",
       "        0.38100502,  0.3832746 ,  0.38554392,  0.38781265,  0.39008113,\n",
       "        0.39234838,  0.39461521,  0.39688109,  0.3991467 ,  0.40141186,\n",
       "        0.40367633,  0.40594011,  0.4082037 ,  0.41046711,  0.4127298 ,\n",
       "        0.41499201,  0.41725376,  0.41951489,  0.42177566,  0.42403608,\n",
       "        0.42629592,  0.42855451,  0.43081272,  0.4330704 ,  0.43532768,\n",
       "        0.43758468,  0.43984132,  0.44209756,  0.44435335,  0.44660897,\n",
       "        0.44886401,  0.45111866,  0.4533732 ,  0.45562729,  0.45788091,\n",
       "        0.46013419,  0.46238719,  0.46464004,  0.46689255,  0.46914487,\n",
       "        0.47139708,  0.47364886,  0.47590034,  0.47815169,  0.48040302,\n",
       "        0.48265411,  0.48490501,  0.48715545,  0.48940571,  0.49165575,\n",
       "        0.49390552,  0.49615525,  0.49840461,  0.50065383,  0.50290302,\n",
       "        0.50515195,  0.50740069,  0.50964931,  0.51189769,  0.51414595,\n",
       "        0.51639385,  0.51864157,  0.52088878,  0.52313592,  0.52538294,\n",
       "        0.5276298 ,  0.52987657,  0.53212318,  0.53436973,  0.53661617,\n",
       "        0.53886248,  0.54110856,  0.54335446,  0.54560027,  0.54784595,\n",
       "        0.55009155,  0.55233707,  0.55458246,  0.55682776,  0.55907291,\n",
       "        0.56131794,  0.56356289,  0.56580784,  0.56805252,  0.57029708,\n",
       "        0.57254144,  0.5747857 ,  0.57702991,  0.57927384,  0.58151771,\n",
       "        0.58376151,  0.58600528,  0.58824887,  0.5904924 ,  0.59273584,\n",
       "        0.59497919,  0.5972225 ,  0.59946568,  0.60170882,  0.60395178,\n",
       "        0.60619468,  0.60843757,  0.61068035,  0.61292302,  0.61516561,\n",
       "        0.61740816,  0.61965058,  0.62189285,  0.62413504,  0.62637714,\n",
       "        0.6286192 ,  0.63086113,  0.63310298,  0.63534467,  0.6375863 ,\n",
       "        0.63982786,  0.64206927,  0.64431059,  0.64655182,  0.64879285,\n",
       "        0.6510336 ,  0.65327435,  0.65551498,  0.65775277,  0.65998889,\n",
       "        0.66222267,  0.66445267,  0.66668216,  0.66891052,  0.67113649,\n",
       "        0.67336142,  0.67558591,  0.67780653,  0.68002612,  0.68224292,\n",
       "        0.68445835,  0.68667264,  0.68888626,  0.69109664,  0.69330486,\n",
       "        0.69550974,  0.69770218,  0.69989199,  0.70207761,  0.70425476,\n",
       "        0.70642718,  0.70858219,  0.71072035,  0.71284363,  0.71495753,\n",
       "        0.71705349,  0.7191189 ,  0.72112289,  0.72312488,  0.72508482,\n",
       "        0.72696822,  0.72883473,  0.73066577,  0.7324751 ,  0.73425041,\n",
       "        0.73601131,  0.73770635,  0.73937484,  0.74099098,  0.74259379,\n",
       "        0.74418749,  0.74574729,  0.74730227,  0.74882889,  0.75034528,\n",
       "        0.75183595,  0.7533218 ,  0.75479763,  0.75626956,  0.75772607,\n",
       "        0.75917331,  0.76061757,  0.76205462,  0.76347889,  0.76489201,\n",
       "        0.76630332,  0.76771247,  0.76911372,  0.77051039,  0.77189584,\n",
       "        0.77326546,  0.77463268,  0.77599259,  0.77734691,  0.778698  ,\n",
       "        0.78003581,  0.78136029,  0.78268286,  0.78400013,  0.78531331,\n",
       "        0.78661985,  0.78792215,  0.7892213 ,  0.79051048,  0.79179514,\n",
       "        0.79307711,  0.79435428,  0.79562945,  0.79689709,  0.79816221,\n",
       "        0.79941647,  0.80066465,  0.80191063,  0.80314458,  0.80437383])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.cumsum()[:320]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, 320 principal components explain about 80% of the variance in the data. Therefore, PCA reduced the dimension of the dataset from almost 900 variables to 320. However, because PCA is a feature extraction method that creates components based on a linear combination of the original features, interpretability is lost as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For the following models, when using the PCA components instead of the original feature space, \n",
    "#we used X_t_train and X_t_test\n",
    "pca = PCA(n_components=320)\n",
    "pca.fit(X_train_scaled)\n",
    "X_t_train = pca.transform(X_train_scaled)\n",
    "X_t_test = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomized Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniellediehl/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:57: DeprecationWarning: Class RandomizedLogisticRegression is deprecated; The class RandomizedLogisticRegression is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   2   4   5  15  78  81  86 112 127 142 145 166 185 186 205 220 238\n",
      " 240 252 274 275 281 282 287 296 298 305 307 312 313 319 320 321 325 328\n",
      " 330 331 333 335 337 345 352 353 356 363 380 389 407 408 409 416 433 434\n",
      " 437 482 485 491 523 538 553 555 563 575 580 590 600 620 637 657 658 659\n",
      " 661 672 682 700 702 704 710 713 718 720 722 724 725 726 736 737 738 739\n",
      " 744 748 764 765 767 768 769 770 774 775 776 779 780 781 783 784 785 786\n",
      " 788 790 791 794 796 797 799 804 806 807 810 811 812 813 814 820 821 835\n",
      " 839 865 892 893]\n"
     ]
    }
   ],
   "source": [
    "#for reason: \n",
    "from sklearn.linear_model import RandomizedLogisticRegression\n",
    "\n",
    "clf = RandomizedLogisticRegression()\n",
    "clf.fit(X_train,y_train_r)\n",
    "\n",
    "#Print the indices of the support features:\n",
    "print clf.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#According to Logistic Regression, which features are important in predicting treatment result?\n",
    "f='  1   2   4   5  51  56  69  81  90  99 113 128 145 148 152 167 186 230 \\\n",
    " 239 240 271 279 280 283 289 290 298 300 307 309 319 321 322 323 330 333 \\\n",
    " 335 337 347 351 354 358 360 365 369 370 391 408 409 410 411 413 435 436 \\\n",
    " 439 440 451 457 460 473 482 495 507 525 544 557 559 565 583 603 644 649 \\\n",
    " 659 684 702 705 706 712 715 720 726 727 728 738 739 741 746 750 766 767 \\\n",
    " 769 770 771 772 777 778 781 783 785 786 787 790 792 793 796 798 799 801 \\\n",
    " 806 809 810 815 816 817 822 823 837 841 847 867 891 894 895'\n",
    "a=[]\n",
    "for i in f.split():\n",
    "    i=int(i)\n",
    "    a.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#use X_train_lr in later models to run only on the selected subset\n",
    "data_lr = data.iloc[:,a]\n",
    "X_lr=data_lr\n",
    "y_los=data['LOS']\n",
    "y_r=data['REASON']\n",
    "\n",
    "X_train_lr, X_test_lr, y_train_los, y_test_los = train_test_split(X_lr,y_los,test_size = 0.33, random_state=42)\n",
    "X_train_lr, X_test_lr, y_train_r, y_test_r = train_test_split(X_lr,y_r,test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#which columns are important? #123 columns\n",
    "print data_lr.columns[:40] \n",
    "#alcdrug, alcflags, CBSA (geo area), detcrim (detailed criminal justice report)\n",
    "#detnlf, division, dsm diagnosis, educ, emp, freq\n",
    "print data_lr.columns[41:80]\n",
    "#age of first use, flags, insurance, PMSA geo area, income source, pay source, source of ref\n",
    "print data_lr.columns[81:]\n",
    "#psy info, race, region, treatment route, service, stfips, substance, age, noprior, numsubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for LENGTH OF STAY\n",
    "clf = RandomizedLogisticRegression()\n",
    "clf.fit(X_train,y_train_los)\n",
    "\n",
    "#Print the indices of the support features:\n",
    "print clf.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g='21  34  47  63  66  67  78 111 120 126 147 164 165 176 178 199 229 231 \\\n",
    "277 278 281 282 283 286 288 291 292 293 298 300 301 303 304 305 306 320 \\\n",
    "322 333 334 336 346 347 349 350 352 356 407 408 416 421 422 424 425 434 \\\n",
    "435 467 470 471 482 518 521 522 531 559 561 578 579 587 589 592 626 649 \\\n",
    "703 711 720 721 722 725 726 741 742 743 744 747 766 767 768 769 770 771 \\\n",
    "772 773 786 791 792 794 799 800 801 804 806 809 810 814 816 818 840 841 \\\n",
    "843 888 890 891'\n",
    "b=[]\n",
    "for i in g.split():\n",
    "    i=int(i)\n",
    "    b.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(b)\n",
    "#112 variables for predicting LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#which columns are important? #112 columns\n",
    "print data_lr_los.columns[:40] \n",
    "#alcdrug, alcflags, CBSA (geo area), detcrim (detailed criminal justice report)\n",
    "#detnlf, division, dsm diagnosis, educ, emp, freq\n",
    "print data_lr_los.columns[41:80]\n",
    "#age of first use, flags, insurance, PMSA geo area, income source, pay source, source of ref\n",
    "print data_lr_los.columns[81:]\n",
    "#psy info, race, region, treatment route, service, stfips, substance, age, noprior, numsubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use X_train_lr in later models to run only on the selected subset\n",
    "data_lr_los = data.iloc[:,b]\n",
    "X_lr_los=data_lr_los\n",
    "y_los=data['LOS']\n",
    "y_r=data['REASON']\n",
    "\n",
    "X_train_lr_los, X_test_lr_los, y_train_los, y_test_los = train_test_split(X_lr_los,y_los,test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length of Stay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM: Support Vector Machines**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing training time for SVM models based on original feature space, PCA feature space, and the reduced feature space from logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.405606060606\n",
      "Time:  7533.04286  seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.clock()\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1)\n",
    "\n",
    "svm_model_linear.fit(X_train, y_train_los)\n",
    "\n",
    "score=svm_model_linear.score(X_test,y_test_los)\n",
    "print score\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.402828282828\n",
      "Time:  20683.008772  seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.clock()\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1)\n",
    "\n",
    "svm_model_linear.fit(X_t_train, y_train_los)\n",
    "\n",
    "score=svm_model_linear.score(X_t_test,y_test_los)\n",
    "print score\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.396161616162\n",
      "Time:  2181.84953  seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.clock()\n",
    "\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1)\n",
    "\n",
    "svm_model_linear.fit(X_train_lr_los, y_train_los)\n",
    "\n",
    "score=svm_model_linear.score(X_test_lr_los,y_test_los)\n",
    "\n",
    "print score\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 0.354595959596\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest Classifier. By convention, clf means 'Classifier'\n",
    "clf = RandomForestClassifier(random_state=0, max_features=30, max_depth=7)\n",
    "\n",
    "# Train the Classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "clf.fit(X_train, y_train_los)\n",
    "\n",
    "# Apply the Classifier we trained to the test data (which, remember, it has never seen before)\n",
    "#clf.predict(X_test)\n",
    "\n",
    "# Create actual english names for the plants for each predicted plant class\n",
    "#preds = clf.predict(X_test)\n",
    "\n",
    "# View a list of the features and their importance scores\n",
    "\n",
    "#print 'train', clf.score(X_train_los, y_train_los, sample_weight=None)\n",
    "\n",
    "print 'test', clf.score(X_test, y_test_los, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP: Multi-Layered Perceptron**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing MLP models based on original feature space, PCA feature space, and reduced feature space from logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.396515151515\n",
      "Time:  46.247193  seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.clock()\n",
    "\n",
    "mlp= MLPClassifier(alpha=1e-1, hidden_layer_sizes=(15,), random_state=1)\n",
    "mlp.fit(X_train, y_train_los) \n",
    "print mlp.score(X_test,y_test_los)\n",
    "\n",
    "print \"Time: \", time.clock() - start, ' seconds'\n",
    "#Why am I now getting 20%??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.394191919192\n",
      "Time:  25.041265  seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.clock()\n",
    "\n",
    "#with pca\n",
    "mlp= MLPClassifier(alpha=1e-1, hidden_layer_sizes=(15,), random_state=1)\n",
    "\n",
    "mlp.fit(X_t_train, y_train_los)\n",
    "#predictions = pipe.predict(features_valid)\n",
    "score=mlp.score(X_t_test,y_test_los)\n",
    "print score\n",
    "\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39398989899\n",
      "Time:  6.652829  seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.clock()\n",
    "\n",
    "#with pca\n",
    "mlp= MLPClassifier(alpha=1e-1, hidden_layer_sizes=(15,), random_state=1)\n",
    "\n",
    "mlp.fit(X_train_lr_los, y_train_los)\n",
    "#predictions = pipe.predict(features_valid)\n",
    "score=mlp.score(X_test_lr_los,y_test_los)\n",
    "print score\n",
    "\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**KNN: K Nearest Neighbors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing KNN model based on original feature space, PCA, and logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.341818181818\n",
      "Time:  234.620227  seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.clock()\n",
    "\n",
    "knn=neighbors.KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train_los)\n",
    "print knn.score(X_test,y_test_los)\n",
    "\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.350656565657\n",
      "Time:  451.860937  seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.clock()\n",
    "\n",
    "knn=neighbors.KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_t_train, y_train_los)\n",
    "\n",
    "score=knn.score(X_t_test,y_test_los)\n",
    "print score \n",
    "\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.359595959596\n",
      "Time:  29.173775  seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.clock()\n",
    "\n",
    "knn=neighbors.KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_train_lr_los, y_train_los)\n",
    "\n",
    "score=knn.score(X_test_lr_los,y_test_los)\n",
    "print score \n",
    "\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XGBOOST- LOS\n",
    "model = XGBClassifier(objective='multi:softmax')#,num_class=9)\n",
    "model.fit(X_train_los, y_train_los)\n",
    "\n",
    "y_pred = model.predict(X_test_los)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(y_test_r, predictions)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models for Predicting Treatment Completion (Reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.683787878788\n",
      "Time:  24.845636  seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "logreg = linear_model.LogisticRegression(penalty='l2',C=1e5)\n",
    "#solver=â€˜newton-cgâ€™\n",
    "# Train the model using the training sets\n",
    "logreg.fit(X_train, y_train_r)\n",
    "#y_pred = regr.predict(X_test)\n",
    "print logreg.score(X_test,y_test_r)\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65803030303\n",
      "Time:  28.057315  seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "#pca = PCA(n_components=320)\n",
    "clf = linear_model.LogisticRegression(penalty='l2',C=1e5) \n",
    "\n",
    "#pipe = Pipeline([('pca', pca), ('logistic', clf)])\n",
    "clf.fit(X_t_train, y_train_r)\n",
    "\n",
    "score=clf.score(X_t_test,y_test_r)\n",
    "print score \n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.685\n",
      "Time:  1.507366  seconds\n"
     ]
    }
   ],
   "source": [
    "#LR subset\n",
    "start = time.clock()\n",
    "\n",
    "clf = linear_model.LogisticRegression(penalty='l2',C=1e5) \n",
    "\n",
    "clf.fit(X_train_lr, y_train_r)\n",
    "\n",
    "score=clf.score(X_test_lr,y_test_r)\n",
    "print score \n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM: Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    32771\n",
      "1    27229\n",
      "Name: REASON, dtype: int64\n",
      "0.546183333333\n"
     ]
    }
   ],
   "source": [
    "print data['REASON'].value_counts()\n",
    "print 32771/float((32771+27229))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.688181818182\n",
      "Time:  8431.688482  seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.clock()\n",
    "\n",
    "svm2 = svm.SVC(gamma=0.001, C=100.)\n",
    "svm2.fit(X_train, y_train_r)  \n",
    "#svm2.predict(X_test_r)\n",
    "print svm2.score(X_test, y_test_r)\n",
    "#scaling the data decreased the score from 68 to 65 \n",
    "\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.560101010101\n",
      "Time:  228.139003  seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.clock()\n",
    "\n",
    "#with PCA\n",
    "pca = PCA(n_components=320)\n",
    "svc = svm.SVC(gamma=0.001, C=100.)\n",
    "\n",
    "pipe = Pipeline([('pca', pca), ('svm', svc)])\n",
    "pipe.fit(X_train_scaled, y_train_r)\n",
    "#predictions = pipe.predict(features_valid)\n",
    "score=pipe.score(X_test_scaled,y_test_r)\n",
    "print score #similar for SVM\n",
    "\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 0.654444444444\n",
      "Time:  1.572092  seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.clock()\n",
    "# Create a random forest Classifier. By convention, clf means 'Classifier'\n",
    "clf = RandomForestClassifier(random_state=0, max_features=40, max_depth=9)\n",
    "\n",
    "clf.fit(X_train, y_train_r)\n",
    "\n",
    "print 'test', clf.score(X_test, y_test_r, sample_weight=None)\n",
    "\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 0.68202020202\n",
      "Time:  1.137784  seconds\n"
     ]
    }
   ],
   "source": [
    "#LR subset\n",
    "start=time.clock()\n",
    "clf = RandomForestClassifier(random_state=0, max_features=40, max_depth=9)\n",
    "\n",
    "clf.fit(X_train_lr, y_train_r)\n",
    "\n",
    "print 'test', clf.score(X_test_lr, y_test_r, sample_weight=None)\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP: Multi-Layered Perceptron**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64080808080808083"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(15,), random_state=1, alpha=1)\n",
    "model.fit(X_train_r_scaled, y_train_r)\n",
    "model.score(X_test_r_scaled,y_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.679191919192\n",
      "Time:  186.033874  seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.clock()\n",
    "\n",
    "mlp= MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15,), random_state=1)\n",
    "mlp.fit(X_train, y_train_r)\n",
    "print mlp.score(X_test,y_test_r)\n",
    "\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666919191919\n",
      "Time:  41.009491  seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.clock()\n",
    "#with PCA\n",
    "\n",
    "mlp= MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15,), random_state=1)\n",
    "\n",
    "mlp.fit(X_t_train, y_train_r)\n",
    "\n",
    "score=mlp.score(X_t_test,y_test_r)\n",
    "print score \n",
    "\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.677272727273\n",
      "Time:  24.916902  seconds\n"
     ]
    }
   ],
   "source": [
    "#LR subset\n",
    "start=time.clock()\n",
    "\n",
    "mlp= MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15,), random_state=1)\n",
    "\n",
    "mlp.fit(X_train_lr, y_train_r)\n",
    "\n",
    "score=mlp.score(X_test_lr,y_test_r)\n",
    "print score \n",
    "\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**KNN: K-Nearest Neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.612575757576\n",
      "Time:  251.798702  seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.clock()\n",
    "\n",
    "knn=neighbors.KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train_r)\n",
    "print knn.score(X_test, y_test_r)\n",
    "\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.634343434343\n",
      "Time:  415.900131  seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.clock()\n",
    "#with PCA\n",
    "knn=neighbors.KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_t_train, y_train_r)\n",
    "\n",
    "score=knn.score(X_t_test,y_test_r)\n",
    "print score \n",
    "\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.628535353535\n",
      "Time:  22.076013  seconds\n"
     ]
    }
   ],
   "source": [
    "#LR subset\n",
    "start=time.clock()\n",
    "#with PCA\n",
    "knn=neighbors.KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_train_lr, y_train_r)\n",
    "\n",
    "score=knn.score(X_test_lr,y_test_r)\n",
    "print score \n",
    "\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBOOST**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing XGBoost accuracy and training time for models based on original feature space, PCA, and reduced set from logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.685101010101\n",
      "Time:  99.946485  seconds\n"
     ]
    }
   ],
   "source": [
    "#XGBOOST- reason\n",
    "start=time.clock()\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train_r)\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(y_test_r, predictions)\n",
    "print accuracy\n",
    "\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.658333333333\n",
      "Time:  109.323209  seconds\n"
     ]
    }
   ],
   "source": [
    "#XGBOOST- reason, PCA\n",
    "start=time.clock()\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_t_train, y_train_r)\n",
    "y_pred=model.predict(X_t_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(y_test_r, predictions)\n",
    "print accuracy\n",
    "\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.688484848485\n",
      "Time:  14.387172  seconds\n"
     ]
    }
   ],
   "source": [
    "#XGBOOST- reason, LR subset\n",
    "start=time.clock()\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train_lr, y_train_r)\n",
    "y_pred=model.predict(X_test_lr)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(y_test_r, predictions)\n",
    "print accuracy\n",
    "\n",
    "print \"Time: \", time.clock() - start, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'subsample': [0.6, 0.9, 1.0], 'learning_rate': [0.05, 0.1, 0.3], 'colsample_bytree': [0.6, 0.9, 1.0], 'max_depth': [3, 6, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_xg={'learning_rate': [0.05, 0.1, 0.3],\n",
    "        'max_depth': [3, 6, 10],\n",
    "        'subsample': [0.6, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.9, 1.0]}\n",
    "grid_xg = GridSearchCV(XGBClassifier(),param_grid_xg,refit=True)\n",
    "grid_xg.fit(X_train, y_train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XGBClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.702929292929\n"
     ]
    }
   ],
   "source": [
    "y_pred=grid_xg.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(y_test_r, predictions)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Gradient Boosting Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69030303030303031"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc=GradientBoostingClassifier(learning_rate=0.3, n_estimators=175, max_depth = 7)\n",
    "gbc=gbc.fit(X_train, y_train_r)\n",
    "sc_val = gbc.score(X_test, y_test_r)\n",
    "sc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining the initial parameter grid to search in\n",
    "param_grid = {'learning_rate': [0.01,.1], 'n_estimators': [100, 200], 'max_depth': [5,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1], 'max_depth': [5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(GradientBoostingClassifier(),param_grid,refit=True)\n",
    "grid.fit(X_train,y_train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70151515151515154"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.001, 0.1], 'max_depth': [3, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'learning_rate': [0.01, 0.001, 0.1], 'n_estimators': [50, 100, 200], 'max_depth': [3, 5,10]}\n",
    "grid = GridSearchCV(GradientBoostingClassifier(),param_grid,refit=True)\n",
    "grid.fit(X_train,y_train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69898989898989894"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
